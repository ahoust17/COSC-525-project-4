{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2adb05c1",
   "metadata": {},
   "source": [
    "# Project 4\n",
    "## Students:\n",
    " > Austin Houston,\n",
    " > Alexander Krneta\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "563a5a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "print(tf.__version__)# you may want to upgrade to 2.10.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddae40d9",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c018f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs to be able to change number of heads?\n",
    "# input to Transformer block is broken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2493f996",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(keras.Model):\n",
    "    def __init__(self, vocab_size, embed_dim=256, num_heads=2, num_blocks=1, ff_dim=256, maxlen=80, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.num_generate = maxlen\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.num_blocks = num_blocks\n",
    "        self.embeddings = None\n",
    "        self.outputs = None\n",
    "\n",
    "        self.inputs = keras.Input(shape=(None, self.embed_dim))\n",
    "\n",
    "\n",
    "    def EmbeddingLayer(self):\n",
    "        # Initialize embeddings\n",
    "        self.token_embedding = layers.Embedding(input_dim=self.vocab_size, output_dim=self.embed_dim, input_length=self.num_generate)\n",
    "        self.positional_embedding = layers.Embedding(input_dim=self.num_generate, output_dim=self.embed_dim, input_length=self.num_generate, embeddings_initializer=keras.initializers.RandomUniform())\n",
    "        self.dropout = layers.Dropout(self.dropout_rate)\n",
    "\n",
    "        position_ids = tf.range(start=0, limit=tf.shape(self.inputs)[-1], delta=1, dtype=tf.int32)\n",
    "        position_embedding = self.positional_embedding(position_ids)\n",
    "        token_embedding = self.token_embedding(self.inputs)\n",
    "        self.embeddings = token_embedding + position_embedding\n",
    "\n",
    "\n",
    "    def TransformerBlock(self):\n",
    "        # Multi-Head Attention layer \n",
    "        # Sums the input to the block and the output from the first dropout\n",
    "        attention = layers.MultiHeadAttention(num_heads=self.num_heads, key_dim=self.embed_dim)(self.embeddings, self.embeddings)\n",
    "        attention = layers.Dropout(rate=self.dropout_rate)(attention)\n",
    "        attention = layers.LayerNormalization(epsilon=1e-6)(layers.Add()([self.embeddings, attention]))\n",
    "        \n",
    "        # Feed-Forward Dense layer\n",
    "        # Sums the output of the first LayerNormalization and second dropout\n",
    "        dense = layers.Dense(units=self.ff_dim, activation='relu')(attention)\n",
    "        dense = layers.Dropout(rate=self.dropout_rate)(dense)\n",
    "        dense = layers.Dense(units=self.embed_dim)(dense)\n",
    "        dense = layers.Dropout(rate=self.dropout_rate)(dense)\n",
    "        dense = layers.LayerNormalization(epsilon=1e-6)(layers.Add()([attention, dense]))\n",
    "\n",
    "        self.outputs = layers.Dense(units=self.embed_dim)(dense)\n",
    "\n",
    "    def create_model(self,vocab_size, embed_dim, num_heads, num_blocks, ff_dim, maxlen, dropout_rate):\n",
    "        \n",
    "        self.EmbeddingLayer()\n",
    "        self.TransformerBlock()\n",
    "\n",
    "        model = tf.keras.models.Model(inputs = self.inputs, outputs=self.outputs)\n",
    "\n",
    "        # Compile the model with sparse categorical crossentropy loss and Adam optimizer\n",
    "        model.compile(\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            optimizer=keras.optimizers.Adam(),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "02fa6ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, None, 256)]  0           []                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_3 (TFOpLamb  (3,)                0           ['input_4[0][0]']                \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3 (Sl  ()                  0           ['tf.compat.v1.shape_3[0][0]']   \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.range_3 (TFOpLambda)        (256,)               0           ['tf.__operators__.getitem_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " embedding_6 (Embedding)        (None, None, 256, 2  2560        ['input_4[0][0]']                \n",
      "                                56)                                                               \n",
      "                                                                                                  \n",
      " embedding_7 (Embedding)        (256, 256)           20480       ['tf.range_3[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, None, 256, 2  0          ['embedding_6[0][0]',            \n",
      " mbda)                          56)                               'embedding_7[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, None, 256, 2  526080     ['tf.__operators__.add_3[0][0]', \n",
      " eadAttention)                  56)                               'tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, None, 256, 2  0           ['multi_head_attention_3[0][0]'] \n",
      "                                56)                                                               \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, None, 256, 2  0           ['tf.__operators__.add_3[0][0]', \n",
      "                                56)                               'dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, None, 256, 2  512        ['add_6[0][0]']                  \n",
      " rmalization)                   56)                                                               \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, None, 256, 2  65792       ['layer_normalization_6[0][0]']  \n",
      "                                56)                                                               \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, None, 256, 2  0           ['dense_9[0][0]']                \n",
      "                                56)                                                               \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, None, 256, 2  65792       ['dropout_14[0][0]']             \n",
      "                                56)                                                               \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, None, 256, 2  0           ['dense_10[0][0]']               \n",
      "                                56)                                                               \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, None, 256, 2  0           ['layer_normalization_6[0][0]',  \n",
      "                                56)                               'dropout_15[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, None, 256, 2  512        ['add_7[0][0]']                  \n",
      " rmalization)                   56)                                                               \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, None, 256, 2  65792       ['layer_normalization_7[0][0]']  \n",
      "                                56)                                                               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 747,520\n",
      "Trainable params: 747,520\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = TransformerModel(vocab_size = 10)\n",
    "model = model.create_model(vocab_size = 100, embed_dim=256, num_heads=2, num_blocks=1, ff_dim=256, maxlen=80, dropout_rate=0.1)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ad747b",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7384cb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, filepath):\n",
    "        with open(filepath, 'r') as f:\n",
    "            self.text = f.read()\n",
    "        self.vocab = None\n",
    "        self.reverse_vocab = None\n",
    "\n",
    "    def prep_text(self):\n",
    "        self.text = self.text.lower()\n",
    "        self.text = ''.join([c for c in self.text if c.isalnum() or c.isspace()])\n",
    "    \n",
    "    def tokenize_text(self):\n",
    "\n",
    "        '''words = np.unique(self.text.split())\n",
    "        self.vocab = {w: i+1 for i, w in enumerate(words)}\n",
    "        self.reverse_vocab = {i+1: w for i, w in enumerate(words)}\n",
    "        self.text = [self.vocab[w] for w in self.text.split()]'''\n",
    "\n",
    "        # Tokenize data\n",
    "        tokenizer = Tokenizer()\n",
    "        tokenizer.fit_on_texts(self.text)\n",
    "        self.sequences = tokenizer.texts_to_sequences(self.text)\n",
    "        # Pad sequences\n",
    "        max_length = 100\n",
    "        self.padded_sequences = pad_sequences(self.sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "  \n",
    "    def create_dataset(self):\n",
    "        self.prep_text()\n",
    "        self.tokenize_text()\n",
    "        # Split data into train and validation sets\n",
    "        self.train_data, self.val_data = train_test_split(self.padded_sequences, test_size=0.2, random_state=42) \n",
    "\n",
    "        #x = np.array(self.text[:-1])\n",
    "        #y = np.array(self.text[1:])\n",
    "        #x = to_categorical(x, num_classes=len(self.vocab)+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cfcb6008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='input_4'), name='input_4', description=\"created by layer 'input_4'\"), but it was called on an input with incompatible shape (32, 100).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/austin/tensorflow_env/env/lib/python3.8/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/austin/tensorflow_env/env/lib/python3.8/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/austin/tensorflow_env/env/lib/python3.8/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/austin/tensorflow_env/env/lib/python3.8/site-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/austin/tensorflow_env/env/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"query\" (type EinsumDense).\n    \n    Shape must be rank 4 but is rank 3\n    \t for 0th input and equation: abcd,def->abcef for '{{node model_3/multi_head_attention_3/query/einsum/Einsum}} = Einsum[N=2, T=DT_FLOAT, equation=\"abcd,def->abcef\"](model_3/tf.__operators__.add_3/AddV2, model_3/multi_head_attention_3/query/einsum/Einsum/ReadVariableOp)' with input shapes: [32,100,256], [256,2,256].\n    \n    Call arguments received by layer \"query\" (type EinsumDense):\n      • inputs=tf.Tensor(shape=(32, 100, 256), dtype=float32)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m data\u001b[38;5;241m.\u001b[39mcreate_dataset()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tensorflow_env/env/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/1h/36qxtl8567zdjv8nzdn4fzrr0000gn/T/__autograph_generated_filenw5xgsok.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/austin/tensorflow_env/env/lib/python3.8/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/austin/tensorflow_env/env/lib/python3.8/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/austin/tensorflow_env/env/lib/python3.8/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/austin/tensorflow_env/env/lib/python3.8/site-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/austin/tensorflow_env/env/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"query\" (type EinsumDense).\n    \n    Shape must be rank 4 but is rank 3\n    \t for 0th input and equation: abcd,def->abcef for '{{node model_3/multi_head_attention_3/query/einsum/Einsum}} = Einsum[N=2, T=DT_FLOAT, equation=\"abcd,def->abcef\"](model_3/tf.__operators__.add_3/AddV2, model_3/multi_head_attention_3/query/einsum/Einsum/ReadVariableOp)' with input shapes: [32,100,256], [256,2,256].\n    \n    Call arguments received by layer \"query\" (type EinsumDense):\n      • inputs=tf.Tensor(shape=(32, 100, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Load text data\n",
    "data = Dataset('beatles.txt')\n",
    "data.create_dataset()\n",
    "# Train the model\n",
    "model.fit(data.train_data, data.train_data, validation_data=(data.val_data, data.val_data), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c3a399",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7aa87d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateText:\n",
    "    def __init__(self, model, vocab):\n",
    "        self.model = model\n",
    "        self.vocab = vocab\n",
    "        self.tokenizer = keras.preprocessing.text.Tokenizer(num_words=len(vocab), char_level=True, oov_token='[UNK]')\n",
    "        self.tokenizer.fit_on_texts(self.vocab)\n",
    "\n",
    "    def generate_text(self, start_string, num_generate=100, temperature=1.0):\n",
    "        #generate text using the model and vocab, start with the start_string and generate num_generate words\n",
    "        # Convert input text to numerical sequence\n",
    "        input_sequence = self.tokenizer.texts_to_sequences([start_string])[0]\n",
    "\n",
    "        # Pad sequence to desired length\n",
    "        input_sequence = keras.preprocessing.sequence.pad_sequences([input_sequence], maxlen=num_generate, truncating='pre')\n",
    "\n",
    "        # Generate output sequence using the model\n",
    "        output_sequence = self.model.predict(input_sequence)[0]\n",
    "\n",
    "        # Apply temperature scaling to the output sequence\n",
    "        output_sequence = output_sequence / temperature\n",
    "        output_sequence = output_sequence ** 2\n",
    "        output_sequence = output_sequence / tf.reduce_sum(output_sequence)\n",
    "\n",
    "        # Sample the next token from the output distribution\n",
    "        sampled_token_index = tf.random.categorical(output_sequence, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        # Convert the sampled token to its corresponding character\n",
    "        sampled_char = self.tokenizer.index_word.get(sampled_token_index, '[UNK]')\n",
    "\n",
    "        # Append the sampled character to the input text and repeat\n",
    "        output_text = start_string + sampled_char\n",
    "        while sampled_char != '[UNK]' and len(output_text) < num_generate:\n",
    "            input_sequence = keras.preprocessing.sequence.pad_sequences([input_sequence], maxlen=num_generate, truncating='pre')\n",
    "            output_sequence = self.model.predict(input_sequence)[0]\n",
    "            output_sequence = output_sequence / temperature\n",
    "            output_sequence = output_sequence ** 2\n",
    "            output_sequence = output_sequence / tf.reduce_sum(output_sequence)\n",
    "            sampled_token_index = tf.random.categorical(output_sequence, num_samples=1)[-1,0].numpy()\n",
    "            sampled_char = self.tokenizer.index_word.get(sampled_token_index, '[UNK]')\n",
    "            output_text += sampled_char\n",
    "\n",
    "        return output_text\n",
    "\n",
    "    def generate_random_text(self, num_generate=100, temperature=1.0):\n",
    "        return self.generate_text('', num_generate=num_generate, temperature=temperature)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd0bd9d",
   "metadata": {},
   "source": [
    "## Task 4: Model Traning and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5537ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model while periodically generating text to show progress\n",
    "def train_model(model, X_train, y_train, X_val, y_val, batch_size=32, epochs=10):\n",
    "    history = model.fit(\n",
    "        x=X_train,\n",
    "        y=y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=(X_val, y_val)\n",
    "    )\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb3b21ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None, 256) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 256), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 100).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/austin/tensorflow_env/env/lib/python3.8/site-packages/keras/engine/training.py\", line 1845, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/austin/tensorflow_env/env/lib/python3.8/site-packages/keras/engine/training.py\", line 1834, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/austin/tensorflow_env/env/lib/python3.8/site-packages/keras/engine/training.py\", line 1823, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/austin/tensorflow_env/env/lib/python3.8/site-packages/keras/engine/training.py\", line 1791, in predict_step\n        return self(x, training=False)\n    File \"/Users/austin/tensorflow_env/env/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"query\" (type EinsumDense).\n    \n    Shape must be rank 4 but is rank 3\n    \t for 0th input and equation: abcd,def->abcef for '{{node model_1/multi_head_attention_1/query/einsum/Einsum}} = Einsum[N=2, T=DT_FLOAT, equation=\"abcd,def->abcef\"](model_1/tf.__operators__.add_1/AddV2, model_1/multi_head_attention_1/query/einsum/Einsum/ReadVariableOp)' with input shapes: [?,100,256], [256,2,256].\n    \n    Call arguments received by layer \"query\" (type EinsumDense):\n      • inputs=tf.Tensor(shape=(None, 100, 256), dtype=float32)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m generate_text \u001b[38;5;241m=\u001b[39m GenerateText(model, data\u001b[38;5;241m.\u001b[39mvocab)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Generate random text\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m random_text \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_text\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_random_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Print the generated text\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(random_text)\n",
      "Cell \u001b[0;32mIn[8], line 44\u001b[0m, in \u001b[0;36mGenerateText.generate_random_text\u001b[0;34m(self, max_length, temperature)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_random_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m):\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_text\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 16\u001b[0m, in \u001b[0;36mGenerateText.generate_text\u001b[0;34m(self, input_text, max_length, temperature)\u001b[0m\n\u001b[1;32m     13\u001b[0m input_sequence \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39msequence\u001b[38;5;241m.\u001b[39mpad_sequences([input_sequence], maxlen\u001b[38;5;241m=\u001b[39mmax_length, truncating\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpre\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Generate output sequence using the model\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m output_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_sequence\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Apply temperature scaling to the output sequence\u001b[39;00m\n\u001b[1;32m     19\u001b[0m output_sequence \u001b[38;5;241m=\u001b[39m output_sequence \u001b[38;5;241m/\u001b[39m temperature\n",
      "File \u001b[0;32m~/tensorflow_env/env/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/1h/36qxtl8567zdjv8nzdn4fzrr0000gn/T/__autograph_generated_filej1_o_k6c.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/austin/tensorflow_env/env/lib/python3.8/site-packages/keras/engine/training.py\", line 1845, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/austin/tensorflow_env/env/lib/python3.8/site-packages/keras/engine/training.py\", line 1834, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/austin/tensorflow_env/env/lib/python3.8/site-packages/keras/engine/training.py\", line 1823, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/austin/tensorflow_env/env/lib/python3.8/site-packages/keras/engine/training.py\", line 1791, in predict_step\n        return self(x, training=False)\n    File \"/Users/austin/tensorflow_env/env/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"query\" (type EinsumDense).\n    \n    Shape must be rank 4 but is rank 3\n    \t for 0th input and equation: abcd,def->abcef for '{{node model_1/multi_head_attention_1/query/einsum/Einsum}} = Einsum[N=2, T=DT_FLOAT, equation=\"abcd,def->abcef\"](model_1/tf.__operators__.add_1/AddV2, model_1/multi_head_attention_1/query/einsum/Einsum/ReadVariableOp)' with input shapes: [?,100,256], [256,2,256].\n    \n    Call arguments received by layer \"query\" (type EinsumDense):\n      • inputs=tf.Tensor(shape=(None, 100, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "data = Dataset('beatles.txt')\n",
    "onehot, tokens, dictionary = data.create_dataset()\n",
    "\n",
    "generate_text = GenerateText(model, data.vocab)\n",
    "\n",
    "# Generate random text\n",
    "random_text = generate_text.generate_random_text()\n",
    "\n",
    "# Print the generated text\n",
    "print(random_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faceae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X and y are your input and target data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model using the training data\n",
    "history = train_model(model, X_train, y_train, X_val, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d6703df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, None, 256)]  0           []                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_1 (TFOpLamb  multiple            0           ['input_2[0][0]']                \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1 (Sl  ()                  0           ['tf.compat.v1.shape_1[0][0]']   \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.range_1 (TFOpLambda)        (256,)               0           ['tf.__operators__.getitem_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, None, 256, 2  2560        ['input_2[0][0]']                \n",
      "                                56)                                                               \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (256, 256)           20480       ['tf.range_1[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, None, 256, 2  0          ['embedding_2[0][0]',            \n",
      " mbda)                          56)                               'embedding_3[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, None, 256, 2  526080     ['tf.__operators__.add_1[0][0]', \n",
      " eadAttention)                  56)                               'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, None, 256, 2  0           ['multi_head_attention_1[0][0]'] \n",
      "                                56)                                                               \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, None, 256, 2  0           ['tf.__operators__.add_1[0][0]', \n",
      "                                56)                               'dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, None, 256, 2  512        ['add_2[0][0]']                  \n",
      " rmalization)                   56)                                                               \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, None, 256, 2  65792       ['layer_normalization_2[0][0]']  \n",
      "                                56)                                                               \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, None, 256, 2  0           ['dense_3[0][0]']                \n",
      "                                56)                                                               \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, None, 256, 2  65792       ['dropout_6[0][0]']              \n",
      "                                56)                                                               \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, None, 256, 2  0           ['dense_4[0][0]']                \n",
      "                                56)                                                               \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, None, 256, 2  0           ['layer_normalization_2[0][0]',  \n",
      "                                56)                               'dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, None, 256, 2  512        ['add_3[0][0]']                  \n",
      " rmalization)                   56)                                                               \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, None, 256, 2  65792       ['layer_normalization_3[0][0]']  \n",
      "                                56)                                                               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 747,520\n",
      "Trainable params: 747,520\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728a7595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243fa1f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "658fa81b",
   "metadata": {},
   "source": [
    "\n",
    "# Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b723a2",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6855b442",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c41dc86",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3812e555",
   "metadata": {},
   "source": [
    "## How to Run Code\n",
    "\n",
    "Please include any special libraries and list your tf version here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad8329fa52fda5ea434e375b521aaa2477bf483cb1e2c0c679e9b1d37b903158"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
